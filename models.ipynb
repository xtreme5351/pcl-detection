{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d37472",
   "metadata": {},
   "source": [
    "## Novel model approach\n",
    "\n",
    "This notebook serves as the source code for all the model testing and training (along with hyperparam grid search) before the development/submission of the final best model. This model approach tries a variation on the transformer architecture, with different heads, as detailed in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e213e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043011bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcl_tf.dataset_manager import DatasetManager as DM\n",
    "from pcl_tf.collation import collate_fn\n",
    "from pcl_tf.tf import warmup_model, get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fd8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 7\n",
    "LOAD_BATCH_SIZE = 16\n",
    "LOCAL_CACHE_DIR = './models_cache'\n",
    "MODEL_NAME = \"albert-base-v2\"\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = False\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd961ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up tokenizer...\n",
      "Warming up encoder (downloads model if needed)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9256fd38743446aaa2f50adff0a124f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mAlbertModel LOAD REPORT\u001b[0m from: albert-base-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "predictions.LayerNorm.weight | UNEXPECTED |  | \n",
      "predictions.LayerNorm.bias   | UNEXPECTED |  | \n",
      "predictions.bias             | UNEXPECTED |  | \n",
      "predictions.dense.weight     | UNEXPECTED |  | \n",
      "predictions.dense.bias       | UNEXPECTED |  | \n",
      "predictions.decoder.bias     | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cache warmup completed.\n"
     ]
    }
   ],
   "source": [
    "print('Warming up tokenizer...')\n",
    "tokenizer = get_tokenizer(MODEL_NAME)\n",
    "\n",
    "print('Warming up encoder (downloads model if needed)...')\n",
    "\n",
    "_ = warmup_model(MODEL_NAME, device=None, cache_dir=LOCAL_CACHE_DIR)\n",
    "print('Model cache warmup completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f976d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_path = \"data/train_semeval_parids-labels.csv\"\n",
    "dev_labels_path = \"data/dev_semeval_parids-labels.csv\"\n",
    "texts_path = \"data/dontpatronizeme_pcl_cleaned.csv\"\n",
    "test_path = \"data/task4_test.tsv\"\n",
    "cats_path = \"data/dontpatronizeme_categories.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07510058",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv(texts_path, low_memory=False)\n",
    "texts_df[\"par_id\"] = texts_df[\"par_id\"].astype(int)\n",
    "texts_df = texts_df.set_index(\"par_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89398ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = DM(train_labels_path, texts_df=texts_df)\n",
    "training_ds.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ds = DM(dev_labels_path, texts_df=texts_df)\n",
    "dev_ds.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47faaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_wrapper(tokenizer):\n",
    "    def collate_fn_inner(batch):\n",
    "        return collate_fn(tokenizer, batch)\n",
    "    return collate_fn_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dev(model, dataloader, device):\n",
    "    model.eval()\n",
    "    bin_probs=[]\n",
    "    bin_labels=[]\n",
    "    multi_probs=[]\n",
    "    multi_labels=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b in dataloader:\n",
    "            input_ids = b[\"input_ids\"].to(device)\n",
    "            attention_mask = b[\"attention_mask\"].to(device)\n",
    "            \n",
    "            labels = b[\"labels\"].to(device)\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            bin_probs.append(torch.sigmoid(out[\"logit_bin\"]).cpu().numpy())\n",
    "            multi_probs.append(torch.sigmoid(out[\"logit_multi\"]).cpu().numpy())\n",
    "            \n",
    "            bin_labels.append(labels[:,0].cpu().numpy())\n",
    "            multi_labels.append(labels[:,1:].cpu().numpy())\n",
    "            \n",
    "    bin_probs = np.concatenate(bin_probs); bin_labels = np.concatenate(bin_labels)\n",
    "    multi_probs = np.concatenate(multi_probs); multi_labels = np.concatenate(multi_labels)\n",
    "    micro_f1 = f1_score(multi_labels.flatten(), (multi_probs>=0.5).astype(int).flatten(), zero_division=0)\n",
    "    return {\"micro_f1\": micro_f1, \"bin_ap\": average_precision_score(bin_labels, bin_probs)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pcl_tf.collation as pcl_collation\n",
    "from pcl_tf.tf import PCLModel, get_tokenizer\n",
    "\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical(\"model_name\", [\"albert-base-v2\", \"microsoft/deberta-v3-small\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    wd = trial.suggest_float(\"wd\", 1e-4, 1e-2, log=True)\n",
    "    max_len = trial.suggest_categorical(\"max_len\", [128, 256])\n",
    "    dropout = 0 # any other dropout value causes grad explosion prob due to small batch size + complex task\n",
    "    epochs = trial.suggest_int(\"epochs\", 3, 10)\n",
    "\n",
    "    trial_tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "    pcl_collation.MAX_LEN = max_len\n",
    "\n",
    "    trial_train_loader = DataLoader(\n",
    "        training_ds,\n",
    "        batch_size=LOAD_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn_wrapper(trial_tokenizer),\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    trial_dev_loader = DataLoader(\n",
    "        dev_ds,\n",
    "        batch_size=LOAD_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn_wrapper(trial_tokenizer),\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    model = PCLModel(model_name, n_labels=NUM_LABELS, dropout=dropout, device=DEVICE).to(DEVICE)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    print(\"Config:\", {\"model_name\": model_name, \"lr\": lr, \"wd\": wd, \"max_len\": max_len, \"dropout\": dropout, \"epochs\": epochs})\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in trial_train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE, non_blocking=True)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE, non_blocking=True)\n",
    "            labels = batch[\"labels\"].to(DEVICE, non_blocking=True)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = out[\"loss\"]\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} - Average Loss: {running_loss / len(trial_train_loader)}\")\n",
    "\n",
    "    metrics = evaluate_dev(model, trial_dev_loader, DEVICE)\n",
    "    micro_f1 = metrics[\"micro_f1\"]\n",
    "    print(\"Trial metrics:\", str(metrics))\n",
    "    return micro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1898784",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaeed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-19 16:46:41,491]\u001b[0m A new study created in memory with name: no-name-6798b5e8-d2f7-4788-8ecc-cd586841645b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'model_name': 'albert-base-v2', 'lr': 3.6915697620432926e-05, 'wd': 0.0005918506109375099, 'max_len': 128, 'dropout': 0, 'epochs': 10}\n",
      "Epoch 1 - Average Loss: 0.3933741569497715\n",
      "Epoch 2 - Average Loss: 0.334785170469234\n",
      "Epoch 3 - Average Loss: 0.24139006980534872\n",
      "Epoch 4 - Average Loss: 0.17194928043212684\n",
      "Epoch 5 - Average Loss: 0.151179707753081\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"pcl_hyperparam_search\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c925fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {best_trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40958365",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for trial in study.trials:\n",
    "    results.append({**trial.params, \"value\": trial.value})\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(\"optuna_results.csv\", index=False)\n",
    "print(\"Saved optuna_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
