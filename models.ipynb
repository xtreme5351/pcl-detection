{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d37472",
   "metadata": {},
   "source": [
    "## Novel model approach\n",
    "\n",
    "This notebook serves as the source code for all the model testing and training (along with hyperparam grid search) before the development/submission of the final best model. This model approach tries a variation on the transformer architecture, with different heads, as detailed in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e213e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043011bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcl_tf.dataset_manager import DatasetManager as DM\n",
    "from pcl_tf.collation import collate_fn\n",
    "from pcl_tf.tf import warmup_model, get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fd8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 7\n",
    "LOAD_BATCH_SIZE = 16\n",
    "LOCAL_CACHE_DIR = './models_cache'\n",
    "MODEL_NAME = \"albert-base-v2\"\n",
    "NUM_WORKERS = 8\n",
    "PIN_MEMORY = False\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd961ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Warming up tokenizer...')\n",
    "tokenizer = get_tokenizer(MODEL_NAME)\n",
    "\n",
    "print('Warming up encoder (downloads model if needed)...')\n",
    "\n",
    "_ = warmup_model(MODEL_NAME, device=None, cache_dir=LOCAL_CACHE_DIR)\n",
    "print('Model cache warmup completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f976d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_path = \"data/train_semeval_parids-labels.csv\"\n",
    "dev_labels_path = \"data/dev_semeval_parids-labels.csv\"\n",
    "texts_path = \"data/dontpatronizeme_pcl_cleaned.csv\"\n",
    "test_path = \"data/task4_test.tsv\"\n",
    "cats_path = \"data/dontpatronizeme_categories.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07510058",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv(texts_path, low_memory=False)\n",
    "texts_df[\"par_id\"] = texts_df[\"par_id\"].astype(int)\n",
    "texts_df = texts_df.set_index(\"par_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89398ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = DM(train_labels_path, texts_df=texts_df)\n",
    "training_ds.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ds = DM(dev_labels_path, texts_df=texts_df)\n",
    "dev_ds.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(MODEL_NAME)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(training_ds, batch_size=LOAD_BATCH_SIZE, shuffle=True, \n",
    "                          collate_fn=lambda b: collate_fn(tokenizer, b), pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
    "\n",
    "dev_loader = DataLoader(dev_ds, batch_size=LOAD_BATCH_SIZE, shuffle=False, \n",
    "                        collate_fn=lambda b: collate_fn(tokenizer, b), pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dev(model, dataloader, device):\n",
    "    model.eval()\n",
    "    bin_probs=[]\n",
    "    bin_labels=[]\n",
    "    multi_probs=[]\n",
    "    multi_labels=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b in dataloader:\n",
    "            input_ids = b[\"input_ids\"].to(device)\n",
    "            attention_mask = b[\"attention_mask\"].to(device)\n",
    "            labels = b[\"labels\"].to(device)\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            bin_probs.append(torch.sigmoid(out[\"logit_bin\"]).cpu().numpy())\n",
    "            multi_probs.append(torch.sigmoid(out[\"logit_multi\"]).cpu().numpy())\n",
    "            bin_labels.append(labels[:,0].cpu().numpy())\n",
    "            multi_labels.append(labels[:,1:].cpu().numpy())\n",
    "            \n",
    "    bin_probs = np.concatenate(bin_probs); bin_labels = np.concatenate(bin_labels)\n",
    "    multi_probs = np.concatenate(multi_probs); multi_labels = np.concatenate(multi_labels)\n",
    "    micro_f1 = f1_score(multi_labels.flatten(), (multi_probs>=0.5).astype(int).flatten(), zero_division=0)\n",
    "    return {\"micro_f1\": micro_f1, \"bin_ap\": average_precision_score(bin_labels, bin_probs)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcl_tf.tf import PCLModel\n",
    "\n",
    "def train_and_eval(config):\n",
    "    model = PCLModel(config[\"model_name\"], n_labels=NUM_LABELS, dropout=config[\"dropout\"], device=DEVICE).to(DEVICE)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"wd\"])\n",
    "    print(\"Model and optimizer created\")\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE, non_blocking=True)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE, non_blocking=True)\n",
    "            labels = batch[\"labels\"].to(DEVICE, non_blocking=True)\n",
    "            optim.zero_grad()\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = out[\"loss\"]\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running += loss.item()\n",
    "        # optionally print per-epoch\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running/len(train_loader)}\")\n",
    "    metrics = evaluate_dev(model, dev_loader, DEVICE)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"model_name\": [\"albert-base-v2\", \"microsoft/deberta-v3-small\"],\n",
    "    \"lr\": [2e-5, 5e-5, 1e-4, 5e-4],\n",
    "    \"wd\": [1e-4, 5e-4, 1e-3, 1e-2, 5e-3],\n",
    "    \"max_len\": [128, 256],\n",
    "    \"dropout\": [0, 0.1, 0.01],\n",
    "    \"epochs\": [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1898784",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaeed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = zip(*grid.items())\n",
    "results = []\n",
    "for combo in tqdm(list(itertools.product(*values)), desc=\"Grid\"):\n",
    "    cfg = dict(zip(keys, combo))\n",
    "    try:\n",
    "        metrics = train_and_eval(cfg)\n",
    "        results.append({**cfg, **metrics})\n",
    "        print(\"CFG:\", cfg, \"=>\", metrics)\n",
    "    except Exception as e:\n",
    "        print(\"Error for cfg\", cfg, \":\", e)\n",
    "        results.append({**cfg, \"error\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(\"grid_results.csv\", index=False)\n",
    "print(\"Saved grid_results.csv\")\n",
    "best_idx = res_df[\"micro_f1\"].idxmax() if \"micro_f1\" in res_df.columns else None\n",
    "if best_idx is not None:\n",
    "    print(\"Best config:\\n\", res_df.loc[best_idx].to_dict())\n",
    "else:\n",
    "    print(\"No successful runs found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
