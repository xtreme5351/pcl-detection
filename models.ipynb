{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d37472",
   "metadata": {},
   "source": [
    "## Novel model approach\n",
    "\n",
    "This notebook serves as the source code for all the model testing and training (along with hyperparam grid search) before the development/submission of the final best model. This model approach tries a variation on the transformer architecture, with different heads, as detailed in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e213e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043011bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcl_tf.dataset_manager import DatasetManager as DM\n",
    "from pcl_tf.collation import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9fd8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = 7\n",
    "LOAD_BATCH_SIZE = 16\n",
    "ACCUM_STEPS = 3  # effective batch size = LOAD_BATCH_SIZE * ACCUM_STEPS = 32\n",
    "LOCAL_CACHE_DIR = './models_cache'\n",
    "MODEL_NAME = \"albert-base-v2\"\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = False\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f976d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_path = \"data/train_semeval_parids-labels.csv\"\n",
    "dev_labels_path = \"data/dev_semeval_parids-labels.csv\"\n",
    "texts_path = \"data/dontpatronizeme_pcl_cleaned.csv\"\n",
    "test_path = \"data/task4_test.tsv\"\n",
    "cats_path = \"data/dontpatronizeme_categories.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07510058",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv(texts_path, low_memory=False)\n",
    "texts_df[\"par_id\"] = texts_df[\"par_id\"].astype(int)\n",
    "texts_df = texts_df.set_index(\"par_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e0ba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auxiliary feature dim: 218 (NER=18, ngram=200)\n"
     ]
    }
   ],
   "source": [
    "from pcl_tf.feature_engineering import build_auxiliary_features, transform_auxiliary_features\n",
    "\n",
    "train_labels = pd.read_csv(train_labels_path)\n",
    "train_par_ids = train_labels[\"par_id\"].astype(int).values\n",
    "train_texts = texts_df.loc[train_par_ids, \"text\"]\n",
    "\n",
    "aux_train, aux_meta = build_auxiliary_features(train_texts, ngram_range=(1, 3),\n",
    "                                                max_features=200, min_df=5)\n",
    "AUX_DIM = aux_meta[\"total_dim\"]\n",
    "print(f\"Auxiliary feature dim: {AUX_DIM} (NER={aux_meta['n_ner']}, ngram={aux_meta['n_ngram']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90986bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels = pd.read_csv(dev_labels_path)\n",
    "dev_par_ids = dev_labels[\"par_id\"].astype(int).values\n",
    "dev_par_ids = dev_par_ids[np.isin(dev_par_ids, texts_df.index)]\n",
    "dev_texts = texts_df.loc[dev_par_ids, \"text\"]\n",
    "aux_dev = transform_auxiliary_features(dev_texts, aux_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89398ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 8375\n",
      "Binary distribution: [7581  794]\n",
      "Multilabel distribution: [574. 160. 162. 192. 145. 363.  29.]\n"
     ]
    }
   ],
   "source": [
    "training_ds = DM(train_labels_path, texts_df=texts_df, aux_features=aux_train)\n",
    "training_ds.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aee088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 2093\n",
      "Binary distribution: [1894  199]\n",
      "Multilabel distribution: [142.  36.  62.  38.  52. 106.  11.]\n"
     ]
    }
   ],
   "source": [
    "dev_ds = DM(dev_labels_path, texts_df=texts_df, aux_features=aux_dev)\n",
    "dev_ds.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d47faaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_wrapper(tokenizer):\n",
    "    def collate_fn_inner(batch):\n",
    "        return collate_fn(tokenizer, batch)\n",
    "    return collate_fn_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dev(model, dataloader, device):\n",
    "    \"\"\"Evaluate model on dev set. Primary metric: F1 of positive (PCL) class.\"\"\"\n",
    "    model.eval()\n",
    "    bin_probs=[]\n",
    "    bin_labels=[]\n",
    "    multi_probs=[]\n",
    "    multi_labels=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b in dataloader:\n",
    "            input_ids = b[\"input_ids\"].to(device)\n",
    "            attention_mask = b[\"attention_mask\"].to(device)\n",
    "            labels = b[\"labels\"].to(device)\n",
    "            aux_features = b[\"aux_features\"].to(device) if \"aux_features\" in b else None\n",
    "\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask, aux_features=aux_features)\n",
    "            \n",
    "            bin_probs.append(torch.sigmoid(out[\"logit_bin\"]).cpu().numpy())\n",
    "            multi_probs.append(torch.sigmoid(out[\"logit_multi\"]).cpu().numpy())\n",
    "            \n",
    "            bin_labels.append(labels[:,0].cpu().numpy())\n",
    "            multi_labels.append(labels[:,1:].cpu().numpy())\n",
    "            \n",
    "    bin_probs = np.concatenate(bin_probs)\n",
    "    bin_labels = np.concatenate(bin_labels)\n",
    "    multi_probs = np.concatenate(multi_probs)\n",
    "    multi_labels = np.concatenate(multi_labels)\n",
    "\n",
    "    # Primary task metric: F1 of positive (PCL) class\n",
    "    bin_preds = (bin_probs >= 0.5).astype(int)\n",
    "    bin_f1 = f1_score(bin_labels, bin_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "    # Secondary diagnostics\n",
    "    multi_micro_f1 = f1_score(multi_labels.flatten(), (multi_probs >= 0.1).flatten(), zero_division=0)\n",
    "    bin_ap = average_precision_score(bin_labels, bin_probs)\n",
    "\n",
    "    return {\"bin_f1\": bin_f1, \"multi_micro_f1\": multi_micro_f1, \"bin_ap\": bin_ap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pcl_tf.collation as pcl_collation\n",
    "from pcl_tf.tf import PCLModel, get_tokenizer\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\")  # for mixed-precision training\n",
    "\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical(\"model_name\", [\"albert-base-v2\", \"microsoft/deberta-v3-small\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    wd = trial.suggest_float(\"wd\", 1e-4, 1e-2, log=True)\n",
    "    max_len = trial.suggest_categorical(\"max_len\", [128, 256])\n",
    "    dropout = 0 # any other dropout value causes grad explosion prob due to small batch size + complex task\n",
    "    epochs = trial.suggest_int(\"epochs\", 3, 12)\n",
    "\n",
    "    trial_tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "    pcl_collation.MAX_LEN = max_len\n",
    "\n",
    "    trial_train_loader = DataLoader(\n",
    "        training_ds,\n",
    "        batch_size=LOAD_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn_wrapper(trial_tokenizer),\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    trial_dev_loader = DataLoader(\n",
    "        dev_ds,\n",
    "        batch_size=LOAD_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn_wrapper(trial_tokenizer),\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    model = PCLModel(model_name, n_labels=NUM_LABELS, aux_dim=AUX_DIM, dropout=dropout, device=DEVICE).to(DEVICE)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    print(\"Config:\", {\"model_name\": model_name, \"lr\": lr, \"wd\": wd, \"max_len\": max_len, \"dropout\": dropout, \"epochs\": epochs, \"accum_steps\": ACCUM_STEPS})\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            optim.zero_grad()\n",
    "\n",
    "            for step, batch in enumerate(trial_train_loader):\n",
    "                input_ids = batch[\"input_ids\"].to(DEVICE, non_blocking=True)\n",
    "                attention_mask = batch[\"attention_mask\"].to(DEVICE, non_blocking=True)\n",
    "                labels = batch[\"labels\"].to(DEVICE, non_blocking=True)\n",
    "                aux_features = batch[\"aux_features\"].to(DEVICE, non_blocking=True) if \"aux_features\" in batch else None\n",
    "\n",
    "                with torch.amp.autocast(\"cuda\"): # fp16 to halve mem usage to avoid oom\n",
    "                    out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, aux_features=aux_features)\n",
    "                    loss = out[\"loss\"] / ACCUM_STEPS\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                running_loss += out[\"loss\"].item()\n",
    "\n",
    "                if (step + 1) % ACCUM_STEPS == 0 or (step + 1) == len(trial_train_loader): # handle odd cases asw\n",
    "                    scaler.step(optim)\n",
    "                    scaler.update()\n",
    "                    optim.zero_grad()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1} - Average Loss: {running_loss / len(trial_train_loader)}\")\n",
    "\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(\"OOM: pruning this trial\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    metrics = evaluate_dev(model, trial_dev_loader, DEVICE)\n",
    "    print(\"Trial metrics:\", str(metrics))\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    return metrics[\"bin_f1\"]  # optimize for F1 of positive (PCL) class — the actual task metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1898784",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaeed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-19 19:12:37,973]\u001b[0m A new study created in memory with name: pcl_hyperparam_search\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'model_name': 'microsoft/deberta-v3-small', 'lr': 0.0009847550584412984, 'wd': 0.0026340358425033694, 'max_len': 128, 'dropout': 0, 'epochs': 12, 'accum_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-19 19:12:40,089]\u001b[0m Trial 0 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOM — pruning this trial\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bc3ebb03324027b9bcdda0fec59a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mAlbertModel LOAD REPORT\u001b[0m from: albert-base-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "predictions.decoder.bias     | UNEXPECTED |  | \n",
      "predictions.LayerNorm.weight | UNEXPECTED |  | \n",
      "predictions.bias             | UNEXPECTED |  | \n",
      "predictions.LayerNorm.bias   | UNEXPECTED |  | \n",
      "predictions.dense.weight     | UNEXPECTED |  | \n",
      "predictions.dense.bias       | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'model_name': 'albert-base-v2', 'lr': 2.5452432531905925e-05, 'wd': 0.0003372757019917842, 'max_len': 256, 'dropout': 0, 'epochs': 7, 'accum_steps': 3}\n",
      "Epoch 1 - Average Loss: 0.28548357745575653\n",
      "Epoch 2 - Average Loss: 0.21269459506845145\n",
      "Epoch 3 - Average Loss: 0.16650328542397336\n",
      "Epoch 4 - Average Loss: 0.10750457924970191\n",
      "Epoch 5 - Average Loss: 0.06740810489926295\n",
      "Epoch 6 - Average Loss: 0.04370970121473305\n",
      "Epoch 7 - Average Loss: 0.03496816375891355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-19 19:18:21,726]\u001b[0m Trial 1 finished with value: 0.1590955806783145 and parameters: {'model_name': 'albert-base-v2', 'lr': 2.5452432531905925e-05, 'wd': 0.0003372757019917842, 'max_len': 256, 'epochs': 7}. Best is trial 1 with value: 0.1590955806783145.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial metrics: {'micro_f1': 0.1590955806783145, 'bin_ap': 0.5121219553541346}\n",
      "Config: {'model_name': 'albert-base-v2', 'lr': 4.4197933894302816e-05, 'wd': 0.000156022902935253, 'max_len': 256, 'dropout': 0, 'epochs': 11, 'accum_steps': 3}\n",
      "Epoch 1 - Average Loss: 0.28941687121311954\n",
      "Epoch 2 - Average Loss: 0.22256851913176393\n",
      "Epoch 3 - Average Loss: 0.15807349091655226\n",
      "Epoch 4 - Average Loss: 0.10286588676530203\n",
      "Epoch 5 - Average Loss: 0.05558376051040095\n",
      "Epoch 6 - Average Loss: 0.02704432423356836\n",
      "Epoch 7 - Average Loss: 0.023363337560605928\n",
      "Epoch 8 - Average Loss: 0.017925359905667525\n",
      "Epoch 9 - Average Loss: 0.028770079984795523\n",
      "Epoch 10 - Average Loss: 0.013773322793624438\n",
      "Epoch 11 - Average Loss: 0.02480191040191991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-19 19:27:12,734]\u001b[0m Trial 2 finished with value: 0.22253653936822254 and parameters: {'model_name': 'albert-base-v2', 'lr': 4.4197933894302816e-05, 'wd': 0.000156022902935253, 'max_len': 256, 'epochs': 11}. Best is trial 2 with value: 0.22253653936822254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial metrics: {'micro_f1': 0.22253653936822254, 'bin_ap': 0.4003592104213016}\n",
      "Config: {'model_name': 'microsoft/deberta-v3-small', 'lr': 0.0009830970384743143, 'wd': 0.0002600234018347784, 'max_len': 128, 'dropout': 0, 'epochs': 6, 'accum_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-19 19:27:14,934]\u001b[0m Trial 3 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOM — pruning this trial\n",
      "Config: {'model_name': 'microsoft/deberta-v3-small', 'lr': 0.0009184137721469565, 'wd': 0.00498768366123752, 'max_len': 256, 'dropout': 0, 'epochs': 7, 'accum_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-19 19:27:16,636]\u001b[0m Trial 4 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-19 19:27:16,792]\u001b[0m Trial 5 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOM — pruning this trial\n",
      "Config: {'model_name': 'albert-base-v2', 'lr': 0.00015421821737335732, 'wd': 0.00957464662719906, 'max_len': 128, 'dropout': 0, 'epochs': 11, 'accum_steps': 3}\n",
      "OOM — pruning this trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2026-02-19 19:27:16,915]\u001b[0m Trial 6 failed with parameters: {'model_name': 'albert-base-v2', 'lr': 1.3151297698966115e-05, 'wd': 0.0005457268146496025, 'max_len': 256, 'epochs': 12} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.65 GiB of which 41.19 MiB is free. Process 10951 has 21.41 MiB memory in use. Including non-PyTorch memory, this process has 6.94 GiB memory in use. Of the allocated memory 6.65 GiB is allocated by PyTorch, and 110.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/venv/lib/python3.13/site-packages/optuna/study/_optimize.py\"\u001b[0m, line \u001b[35m206\u001b[0m, in \u001b[35m_run_trial\u001b[0m\n",
      "    value_or_values = func(trial)\n",
      "  File \u001b[35m\"/tmp/ipykernel_13546/2898905448.py\"\u001b[0m, line \u001b[35m37\u001b[0m, in \u001b[35mobjective\u001b[0m\n",
      "    model = \u001b[31mPCLModel\u001b[0m\u001b[1;31m(model_name, n_labels=NUM_LABELS, aux_dim=AUX_DIM, dropout=dropout, device=DEVICE)\u001b[0m.to(DEVICE)\n",
      "            \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/pcl_tf/tf.py\"\u001b[0m, line \u001b[35m75\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "    self.encoder = \u001b[31mget_encoder\u001b[0m\u001b[1;31m(encoder_name, device=device)\u001b[0m\n",
      "                   \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/pcl_tf/tf.py\"\u001b[0m, line \u001b[35m53\u001b[0m, in \u001b[35mget_encoder\u001b[0m\n",
      "    \u001b[31mmodel.to\u001b[0m\u001b[1;31m(device)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/venv/lib/python3.13/site-packages/transformers/modeling_utils.py\"\u001b[0m, line \u001b[35m3520\u001b[0m, in \u001b[35mto\u001b[0m\n",
      "    return \u001b[31msuper().to\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1381\u001b[0m, in \u001b[35mto\u001b[0m\n",
      "    return \u001b[31mself._apply\u001b[0m\u001b[1;31m(convert)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m933\u001b[0m, in \u001b[35m_apply\u001b[0m\n",
      "    \u001b[31mmodule._apply\u001b[0m\u001b[1;31m(fn)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m933\u001b[0m, in \u001b[35m_apply\u001b[0m\n",
      "    \u001b[31mmodule._apply\u001b[0m\u001b[1;31m(fn)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m933\u001b[0m, in \u001b[35m_apply\u001b[0m\n",
      "    \u001b[31mmodule._apply\u001b[0m\u001b[1;31m(fn)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^\u001b[0m\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m964\u001b[0m, in \u001b[35m_apply\u001b[0m\n",
      "    param_applied = fn(param)\n",
      "  File \u001b[35m\"/home/pranav/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[35m1367\u001b[0m, in \u001b[35mconvert\u001b[0m\n",
      "    return \u001b[31mt.to\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "           \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mdevice,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^\u001b[0m\n",
      "        \u001b[1;31mdtype if t.is_floating_point() or t.is_complex() else None,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        \u001b[1;31mnon_blocking,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "\u001b[1;35mtorch.OutOfMemoryError\u001b[0m: \u001b[35mCUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.65 GiB of which 41.19 MiB is free. Process 10951 has 21.41 MiB memory in use. Including non-PyTorch memory, this process has 6.94 GiB memory in use. Of the allocated memory 6.65 GiB is allocated by PyTorch, and 110.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\u001b[0m\n",
      "\u001b[33m[W 2026-02-19 19:27:16,918]\u001b[0m Trial 6 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.65 GiB of which 41.19 MiB is free. Process 10951 has 21.41 MiB memory in use. Including non-PyTorch memory, this process has 6.94 GiB memory in use. Of the allocated memory 6.65 GiB is allocated by PyTorch, and 110.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, study_name=\u001b[33m\"\u001b[39m\u001b[33mpcl_hyperparam_search\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/optuna/study/_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     19\u001b[39m trial_train_loader = DataLoader(\n\u001b[32m     20\u001b[39m     training_ds,\n\u001b[32m     21\u001b[39m     batch_size=LOAD_BATCH_SIZE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     num_workers=NUM_WORKERS,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m trial_dev_loader = DataLoader(\n\u001b[32m     29\u001b[39m     dev_ds,\n\u001b[32m     30\u001b[39m     batch_size=LOAD_BATCH_SIZE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     num_workers=NUM_WORKERS,\n\u001b[32m     35\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m model = \u001b[43mPCLModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_LABELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAUX_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m.to(DEVICE)\n\u001b[32m     38\u001b[39m optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConfig:\u001b[39m\u001b[33m\"\u001b[39m, {\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m: model_name, \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr, \u001b[33m\"\u001b[39m\u001b[33mwd\u001b[39m\u001b[33m\"\u001b[39m: wd, \u001b[33m\"\u001b[39m\u001b[33mmax_len\u001b[39m\u001b[33m\"\u001b[39m: max_len, \u001b[33m\"\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m\"\u001b[39m: dropout, \u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m: epochs, \u001b[33m\"\u001b[39m\u001b[33maccum_steps\u001b[39m\u001b[33m\"\u001b[39m: ACCUM_STEPS})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/pcl_tf/tf.py:75\u001b[39m, in \u001b[36mPCLModel.__init__\u001b[39m\u001b[34m(self, encoder_name, n_labels, aux_dim, dropout, device)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoder_name, n_labels, aux_dim, dropout=\u001b[32m0.1\u001b[39m, device: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28mself\u001b[39m.encoder = \u001b[43mget_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     hidden = \u001b[38;5;28mself\u001b[39m.encoder.config.hidden_size\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m.aux_dim = aux_dim\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/pcl_tf/tf.py:53\u001b[39m, in \u001b[36mget_encoder\u001b[39m\u001b[34m(model_name, device, cache_dir)\u001b[39m\n\u001b[32m     51\u001b[39m model.load_state_dict(sd)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/transformers/modeling_utils.py:3520\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3515\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   3516\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3517\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3518\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3519\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3520\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1381\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1378\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1379\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:933\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:933\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n",
      "    \u001b[31m[... skipping similar frames: Module._apply at line 933 (3 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:933\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:964\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    960\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    961\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    962\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    965\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    967\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/pcl-detection/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1367\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1361\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1362\u001b[39m             device,\n\u001b[32m   1363\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1364\u001b[39m             non_blocking,\n\u001b[32m   1365\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1366\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.65 GiB of which 41.19 MiB is free. Process 10951 has 21.41 MiB memory in use. Including non-PyTorch memory, this process has 6.94 GiB memory in use. Of the allocated memory 6.65 GiB is allocated by PyTorch, and 110.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"pcl_hyperparam_search\")\n",
    "study.optimize(objective, n_trials=50, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c925fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {best_trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40958365",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for trial in study.trials:\n",
    "    results.append({**trial.params, \"value\": trial.value})\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(\"optuna_results.csv\", index=False)\n",
    "print(\"Saved optuna_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
